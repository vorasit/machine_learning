{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "นำข้อมูล Test set เข้าทำนาย และได้ผลลัพธ์ y_pred (y_predict) \n",
    "\n",
    "Note: <b>สนใจ/Focus หาอะไร ให้สิ่งนั้นเป็น Positive</b>\n",
    "- ระบบตรวจจับกำจัดเมล์ขยะ สนใจ (Focus หา) Spam : ให้ Spam = Positive \n",
    "- ระบบตรวจหาผู้ป่วย สนใจ (Focus หา) ผู้ป่วย : ให้ผล ป่วย = Positive \n",
    "- ระบบตรวจหาสินค้าดี : ให้ของดี = Positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model ... สมมุติว่าส่วนนี้ทำการ Train สร้าง Model เรียบร้อยแล้ว\n",
    "# model.fit(X, y)\n",
    "\n",
    "# y_pred = model.predict(X_test) ทำการทำนาย (สมมุติว่าทำนายแล้วได้ดัง y_pred ด้านล่าง)\n",
    "\n",
    "# ค่า Label และความหมาย  0=Bad, 1=Good\n",
    "y_targets = ['Bad','Good']\n",
    "\n",
    "y_true = [0, 1, 0, 1, 0, 0, 1, 0, 0, 1]     # ค่า Label จริงของข้อมูล (y_test)\n",
    "y_pred = [0, 1, 0, 1, 0, 1, 1, 0, 1, 0]     # Label ที่ได้จากการทำนายของ Model (ผลการ Predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy = ที่ทำนายถูก/ทั้งหมด = (TP+TN) / All\n",
    "(3+4)/10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision\n",
    "สนใจผลที่ทำนาย (Prediction) ว่ามีความถูกต้องแม่นยำเท่าใด"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision (Positive) = TP / (TP+FP)\n",
    "Pp = 3/(3+2)\n",
    "Pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision (Positive) = TP / (TP+FP)\n",
    "# Precision (Negative) = TN / (TN+FN)\n",
    "Pn = 4/(4+1)\n",
    "Pn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recall\n",
    "พิจารณาเทียบกับของจริง (Actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recall (Positive) = TP / (TP+FN)\n",
    "Rp = 3/(3+1)\n",
    "Rp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recall (Positive) = TP / (TP+FN)\n",
    "# Recall (Negative) = TN / (TN+FP)\n",
    "Rn = 4/(4+2)\n",
    "Rn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1 score = 2.Precision.Recall/(Precision + Recall)\n",
    "# Positive\n",
    "2 * Pp * Rp / (Pp + Rp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1 score = 2.Precision.Recall/(Precision + Recall)\n",
    "# Negative\n",
    "2 * Pn * Rn / (Pn + Rn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-learn\n",
    "ใช้ไลบรารี แสดงตาราง Confusion Matrix และ คำนวณค่าต่าง ๆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0=Bad, 1=Good   แทนค่าด้วย 0 1 เพื่อให้ดูง่ายขึ้น (กำหนดเป็นอะไรก็ได้ตามที่ใช้งาน)\n",
    "y_targets = ['Bad','Good']\n",
    "\n",
    "print('Accuracy Score:', accuracy_score(y_true, y_pred))\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=y_targets))\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TN = cm[0, 0]\n",
    "FP = cm[0, 1]\n",
    "FN = cm[1, 0]\n",
    "TP = cm[1, 1]\n",
    "TN, FP, FN, TP\n",
    "# cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_p = TP/(TP+FP)\n",
    "precision_n = TN/(TN+FN)\n",
    "recall_p = TP/(TP+FN)\n",
    "recall_n = TN/(TN+FP)\n",
    "accuracy = (TP+TN)/(TP+TN+FP+FN)\n",
    "print('Accuracy:', accuracy)\n",
    "print('Precision (Positive or Good):', precision_p)\n",
    "print('Precision (Negative or Bad):', precision_n)\n",
    "print('Recall (Positive or Good):', recall_p)\n",
    "print('Recall (Negative or Bad):', recall_n.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scikit-learn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# y_targets = ['Bad','Good']\n",
    "# labels = ['Bad','Good']     #\n",
    "labels = ['No','Yes']       # COVID-19\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "ConfusionMatrixDisplay(cm, display_labels=labels).plot()\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "ax = plt.subplot()\n",
    "\n",
    "plt.rcParams['figure.figsize'] = 5, 4  \n",
    "plt.rcParams.update({'font.size':14})  \n",
    "\n",
    "sns.heatmap(cm, annot=True, ax=ax, cmap=\"coolwarm\") #annot=True to annotate cells\n",
    "ax.set_xlabel('Predicted labels')\n",
    "ax.set_ylabel('Actual (True)'); \n",
    "ax.set_title('Confusion Matrix'); \n",
    "ax.xaxis.set_ticklabels(y_targets)\n",
    "ax.yaxis.set_ticklabels(y_targets)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda list scikit-plot\n",
    "# !pip show scikit-plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-plot\n",
    "# !conda install -c conda-forge scikit-plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scikit-plot\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import scikitplot as skplot\n",
    "skplot.metrics.plot_confusion_matrix(y_true, y_pred)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Class (Catgories)\n",
    "Cat, Dog, Bird"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ws03\n",
    "\n",
    "# create model ... สมมุติว่าส่วนนี้ทำการ Train สร้าง Model เรียบร้อยแล้ว\n",
    "# model.fit(X, y)\n",
    "\n",
    "# model.score(X, y) คำนวณค่าความแม่นยำ\n",
    "# y_pred = model.predict(X_test) ทำการทำนาย (สมมุติว่าทำนายแล้วได้ดัง y_pred ด้านล่าง)\n",
    "\n",
    "\n",
    "y_targets = ['Cat','Dog','Bird']\n",
    "\n",
    "y_true = [0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 2, 2, 2, 2, 2]\n",
    "y_pred = [0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 2, 2, 2, 1, 2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scikit-learn\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "labels = ['Cat','Dog','Bird']       # \n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "ConfusionMatrixDisplay(cm, display_labels=labels).plot()\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "print('Accuracy Score: {:.3f}'.format(accuracy_score(y_true, y_pred)))\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=y_targets))\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.subplot()\n",
    "\n",
    "plt.rcParams['figure.figsize'] = 5, 4 \n",
    "plt.rcParams.update({'font.size':14}) \n",
    "\n",
    "sns.heatmap(cm, annot=True, ax = ax, cmap=\"coolwarm\") #annot=True to annotate cells\n",
    "ax.set_xlabel('Predicted labels')\n",
    "ax.set_ylabel('Actual (True)'); \n",
    "ax.set_title('Confusion Matrix'); \n",
    "ax.xaxis.set_ticklabels(y_targets)\n",
    "ax.yaxis.set_ticklabels(y_targets)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scikitplot as skplot\n",
    "skplot.metrics.plot_confusion_matrix(y_true, y_pred, normalize=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('y_true: ', y_true)\n",
    "print('y_pred: ', y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
